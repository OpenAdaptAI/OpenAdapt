""" hello
Implements a playback strategy wherein the next InputEvents are generated by showing
ScreenShots and InputEvents to Minigpt-4 and giving it a text description of the goal
to be accomplished.
"""

from pprint import pformat
import time

from loguru import logger
import mss.base

import sys
sys.path.append('../puterbot')
from puterbot.events import get_events
from puterbot.utils import display_event, rows2dicts
from puterbot.models import Recording, Screenshot
from puterbot.strategies.ocr_mixin import OCRReplayStrategyMixin

from MiniGPT4.minigpt4.common.config import Config
from MiniGPT4.minigpt4.common.dist_utils import get_rank
from MiniGPT4.minigpt4.common.registry import registry
from MiniGPT4.minigpt4.conversation.conversation import Chat, CONV_VISION

DISPLAY_EVENTS = False
REPLAY_EVENTS = True
SLEEP = True

from typing import List, Union
import itertools

from loguru import logger
from PIL import Image
from rapidocr_onnxruntime import RapidOCR
from sklearn.cluster import DBSCAN
import numpy as np
import pandas as pd

import argparse
import random

import torch
import torch.backends.cudnn as cudnn


class GPTReplayStrategy(OCRReplayStrategyMixin):

    def __init__(
            self,
            recording: Recording,
            display_events=DISPLAY_EVENTS,
            replay_events=REPLAY_EVENTS,
            sleep=SLEEP,
    ):
        super().__init__(recording)
        self.display_events = display_events
        self.replay_events = replay_events
        self.sleep = sleep
        self.prev_timestamp = None
        self.input_event_idx = -1
        self.processed_input_events = get_events(recording, process=True)
        event_dicts = rows2dicts(self.processed_input_events)
        logger.info(f"event_dicts=\n{pformat(event_dicts)}")

    def get_next_input_event(
            self,
            screenshot: Screenshot,
    ):
        self.input_event_idx += 1
        num_input_events = len(self.processed_input_events)
        if self.input_event_idx >= num_input_events:
            # TODO: refactor
            raise StopIteration()

        # get description of the screenshot using ocr_mixin
        text = self.get_ocr_text(screenshot)

        # get prev InputEvents text
        # TODO: may have to alter this to allow for more descriptive answers from MiniGPT-4
        previously_recorded_input_events = ""
        for event in self.processed_input_events[:self.input_event_idx]:
            if previously_recorded_input_events != "":
                previously_recorded_input_events += ", "
            previously_recorded_input_events += event.text

        # feed recording.task_description, current screenshot, and past InputEvents to
        # MiniGPT4 to generate the next InputEvent

        # Model Initialization from MiniGPT4 demo.py
        args = parse_args()
        cfg = Config(args)

        model_config = cfg.model_cfg
        model_config.device_8bit = args.gpu_id
        model_cls = registry.get_model_class(model_config.arch)
        model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))

        vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train
        vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(
            vis_processor_cfg)
        chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id))

        # upload screenshot
        chat_state = CONV_VISION.copy()
        img_list = []
        chat.upload_img(screenshot, chat_state, img_list)

        # ask question
        user_message = "Please generate the next input event based on the following:\n\n" \
                       "Task goal: {}\n\n" \
                       "Previously recorded input events: {}\n\n" \
                       "Screenshot description: {}\n\n" \
                       "Please provide your input event below." \
            .format(self.recording.task_description,
                    previously_recorded_input_events, text)
        chat.ask(user_message, chat_state)

        # get answer as a string
        llm_message = chat.answer(conv=chat_state,
                                  img_list=img_list,
                                  num_beams=1,
                                  temperature=1,
                                  max_new_tokens=300,
                                  max_length=2000)[0]

        # TODO: create InputEvent from llm_message and return it

        # TODO: might need to change this part
        input_event = self.processed_input_events[self.input_event_idx]
        logger.info(
            f"{self.input_event_idx=} of {num_input_events=}: {input_event=}"
        )

        # for displaying/replaying events

        if self.display_events:
            image = display_event(input_event)
            image.show()
        if self.replay_events:
            if self.sleep and self.prev_timestamp:
                sleep_time = input_event.timestamp - self.prev_timestamp
                logger.debug(f"{sleep_time=}")
                time.sleep(sleep_time)
            self.prev_timestamp = input_event.timestamp
            return input_event
        else:
            return None


def parse_args():
    parser = argparse.ArgumentParser(description="Demo")
    parser.add_argument("--cfg-path", required=True, help="path to configuration file.")
    parser.add_argument("--gpu-id", type=int, default=0, help="specify the gpu to load the model.")
    parser.add_argument(
        "--options",
        nargs="+",
        help="override some settings in the used config, the key-value pair "
             "in xxx=yyy format will be merged into config file (deprecate), "
             "change to --cfg-options instead.",
    )
    args = parser.parse_args()
    return args


def setup_seeds(config):
    seed = config.run_cfg.seed + get_rank()

    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)

    cudnn.benchmark = False
    cudnn.deterministic = True
